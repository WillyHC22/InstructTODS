{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import openai\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from collections import OrderedDict\n",
    "\n",
    "def format_baseline_results(bart_results, other_results):\n",
    "\n",
    "    reformatted_results = {}\n",
    "    for idx, sample in enumerate(bart_results):\n",
    "        cur_results = {} #processed_preds, gold_intent\n",
    "        labels = sample[\"labels\"]\n",
    "        processed_pred = {\"top1\":labels[0].replace(\" \", \"_\"),\n",
    "                        \"top2\":labels[1].replace(\" \", \"_\"),\n",
    "                        \"top3\":labels[2].replace(\" \", \"_\")}\n",
    "        gold_intent = other_results[str(idx)][\"gold_intent\"]\n",
    "        cur_results[\"gold_intent\"] = gold_intent\n",
    "        cur_results[\"processed_pred\"] = processed_pred\n",
    "        reformatted_results[str(idx)] = cur_results\n",
    "    return reformatted_results\n",
    "\n",
    "def print_samples(results, intent):\n",
    "    correct_count = 0\n",
    "    sample_count = 0\n",
    "    for k, v in results.items():\n",
    "        if v[\"gold_intent\"] == intent:\n",
    "            sample_count += 1\n",
    "            print(v[\"text\"])\n",
    "            print(v[\"processed_pred\"])\n",
    "            if v[\"gold_intent\"] == v[\"processed_pred\"][\"top1\"]:\n",
    "                correct_count += 1\n",
    "\n",
    "    print(f\"Total of {correct_count} predicted correctly out of {sample_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Banking77\n",
    "# gpt3_top3 = json.load(open(\"/home/willy/instructod/src/IC/results/banking77/full_banking77_top3_gpt3.5_processed.json\", \"r\"))\n",
    "# gpt3_top1 = json.load(open(\"/home/willy/instructod/src/IC/results/banking77/full_banking77_top1_gpt3.5_processed.json\", \"r\"))\n",
    "# gpt4_top3 = json.load(open(\"/home/willy/instructod/src/IC/results/banking77/full_banking77_top3_gpt4_processed.json\", \"r\"))\n",
    "# gpt4_top1 = json.load(open(\"/home/willy/instructod/src/IC/results/banking77/full_banking77_top1_gpt4_processed.json\", \"r\"))\n",
    "# bart_corr = format_baseline_results(json.load(open(\"/home/willy/instructod/src/IC/results/baselines/bart-large-mnli-intent-correct.json\", \"r\")), gpt3_top1)\n",
    "# bart = format_baseline_results(json.load(open(\"/home/willy/instructod/src/IC/results/baselines/bart-large-mnli.json\", \"r\")), gpt3_top1)\n",
    "\n",
    "#CLINC150\n",
    "gpt3_top3 = json.load(open(\"/home/willy/instructod/src/IC/results/clinc150/full_clinc150_top3_gpt3.5_processed.json\", \"r\"))\n",
    "gpt3_top1 = json.load(open(\"/home/willy/instructod/src/IC/results/clinc150/full_clinc150_top1_gpt3.5_processed.json\", \"r\"))\n",
    "gpt4_top3 = json.load(open(\"/home/willy/instructod/src/IC/results/clinc150/full_clinc150_top3_gpt4_processed.json\", \"r\"))\n",
    "gpt4_top1 = json.load(open(\"/home/willy/instructod/src/IC/results/clinc150/full_clinc150_top1_gpt4_processed.json\", \"r\"))\n",
    "bart_corr = format_baseline_results(json.load(open(\"/home/willy/instructod/src/IC/results/baselines/bart-large-mnli_intent-correct_clinc150.json\", \"r\")), gpt3_top1)\n",
    "bart = format_baseline_results(json.load(open(\"/home/willy/instructod/src/IC/results/baselines/bart-large-mnli_clinc150.json\", \"r\")), gpt3_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\"gpt3_top3\":gpt3_top3,\n",
    "               \"gpt3_top1\":gpt3_top1,\n",
    "               \"gpt4_top3\":gpt4_top3,\n",
    "               \"gpt4_top1\":gpt4_top1,\n",
    "               \"bart\":bart,\n",
    "               \"bart_corr\":bart_corr}\n",
    "\n",
    "def update(dict_res, intent, setting):\n",
    "    if intent not in dict_res:\n",
    "        dict_res[intent] = {}\n",
    "    try:\n",
    "        dict_res[intent][setting] += 1\n",
    "    except:\n",
    "        dict_res[intent][setting] = 1\n",
    "    return dict_res\n",
    "\n",
    "def get_repartition(results):\n",
    "    comparative_results = {}\n",
    "    for k, v in results.items():\n",
    "        gold = v[\"gold_intent\"]\n",
    "        if \"top1\" in v[\"processed_pred\"]:\n",
    "            top1 = v[\"processed_pred\"][\"top1\"]\n",
    "        else:\n",
    "            top1 = None\n",
    "        if \"top2\" in v[\"processed_pred\"]:\n",
    "            top2 = v[\"processed_pred\"][\"top2\"]\n",
    "        else:\n",
    "            top2 = None\n",
    "        if \"top3\" in v[\"processed_pred\"]:\n",
    "            top3 = v[\"processed_pred\"][\"top3\"]\n",
    "        else:\n",
    "            top3 = None\n",
    "\n",
    "        if top1 and gold == top1:\n",
    "            comparative_results = update(comparative_results, gold, \"gpt3_top1\")\n",
    "        elif top2 and gold == top2:\n",
    "            comparative_results = update(comparative_results, gold, \"gpt3_top2\")\n",
    "        elif top3 and gold == top3:\n",
    "            comparative_results = update(comparative_results, gold, \"gpt3_top3\")\n",
    "\n",
    "        else:\n",
    "            #completely missclassed\n",
    "            if gold not in comparative_results:\n",
    "                comparative_results[gold] = {}\n",
    "            try:\n",
    "                comparative_results[gold][\"gpt3_multi_fail\"] += 1\n",
    "            except:\n",
    "                comparative_results[gold][\"gpt3_multi_fail\"] = 1\n",
    "    return comparative_results\n",
    "\n",
    "def print_fail(processed_results, threshold):\n",
    "    count_total = 0\n",
    "    total_fail_count = 0\n",
    "    for k, v in processed_results.items():\n",
    "        # for k1, v1 in v.items():\n",
    "        if \"gpt3_multi_fail\" not in v:\n",
    "            continue\n",
    "        fail_count = v[\"gpt3_multi_fail\"]\n",
    "        if fail_count >= threshold:\n",
    "            print(k, fail_count)\n",
    "            count_total += 1\n",
    "            total_fail_count += fail_count\n",
    "    print(f\"There are {count_total} misclassified for a threshold of {threshold}\")\n",
    "    print(f\"There are {total_fail_count} total fail count for mistakes with a thrshold above {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results_gpt3 = get_repartition(gpt3_top3)\n",
    "processed_results_gpt4 = get_repartition(gpt4_top3)\n",
    "processed_results_gpt3_1 = get_repartition(gpt3_top1)\n",
    "processed_results_gpt4_1 = get_repartition(gpt4_top1)\n",
    "processed_results_bart = get_repartition(bart)\n",
    "processed_results_bart_corr = get_repartition(bart_corr)\n",
    "# print(json.dumps(processed_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt3-3\n",
      "calendar 25\n",
      "reminder_update 26\n",
      "calories 23\n",
      "how_busy 30\n",
      "oos 1000\n",
      "There are 5 misclassified for a threshold of 23\n",
      "There are 1104 total fail count for mistakes with a thrshold above 23\n",
      "===============\n",
      "gpt4-3\n",
      "oos 113\n",
      "There are 1 misclassified for a threshold of 23\n",
      "There are 113 total fail count for mistakes with a thrshold above 23\n",
      "===============\n",
      "gpt3-1\n",
      "distance 25\n",
      "insurance 25\n",
      "reminder 28\n",
      "food_last 24\n",
      "calories 30\n",
      "tire_change 24\n",
      "how_busy 26\n",
      "gas 26\n",
      "oos 1000\n",
      "There are 9 misclassified for a threshold of 23\n",
      "There are 1208 total fail count for mistakes with a thrshold above 23\n",
      "===============\n",
      "gpt4-1\n",
      "distance 25\n",
      "spending_history 30\n",
      "no 25\n",
      "pto_used 25\n",
      "reminder_update 30\n",
      "ingredient_substitution 24\n",
      "todo_list 24\n",
      "goodbye 23\n",
      "cancel 25\n",
      "gas 26\n",
      "oos 379\n",
      "There are 11 misclassified for a threshold of 23\n",
      "There are 636 total fail count for mistakes with a thrshold above 23\n",
      "===============\n",
      "gpt_bart\n",
      "insurance_change 24\n",
      "improve_credit_score 27\n",
      "fun_fact 26\n",
      "change_user_name 27\n",
      "shopping_list_update 30\n",
      "rollover_401k 24\n",
      "user_name 29\n",
      "next_song 23\n",
      "restaurant_suggestion 23\n",
      "rewards_balance 29\n",
      "new_card 30\n",
      "todo_list_update 29\n",
      "calculator 30\n",
      "pto_used 23\n",
      "schedule_maintenance 26\n",
      "travel_notification 25\n",
      "sync_device 25\n",
      "food_last 26\n",
      "reminder_update 30\n",
      "make_call 23\n",
      "bill_due 24\n",
      "schedule_meeting 27\n",
      "next_holiday 26\n",
      "order_status 25\n",
      "pin_change 25\n",
      "last_maintenance 27\n",
      "meeting_schedule 29\n",
      "ingredients_list 27\n",
      "smart_home 30\n",
      "book_hotel 29\n",
      "pto_balance 30\n",
      "credit_limit_change 29\n",
      "book_flight 23\n",
      "bill_balance 30\n",
      "redeem_rewards 25\n",
      "calendar_update 30\n",
      "are_you_a_bot 23\n",
      "expiration_date 25\n",
      "update_playlist 23\n",
      "cancel_reservation 23\n",
      "change_ai_name 29\n",
      "car_rental 23\n",
      "meal_suggestion 28\n",
      "order_checks 30\n",
      "oos 964\n",
      "There are 45 misclassified for a threshold of 23\n",
      "There are 2133 total fail count for mistakes with a thrshold above 23\n",
      "===============\n",
      "gpt_bart_corr\n",
      "translate 27\n",
      "payday 24\n",
      "user_name 27\n",
      "todo_list_update 23\n",
      "uber 28\n",
      "calculator 30\n",
      "pto_used 24\n",
      "food_last 24\n",
      "restaurant_reviews 25\n",
      "next_holiday 23\n",
      "last_maintenance 23\n",
      "report_fraud 23\n",
      "smart_home 30\n",
      "pto_balance 29\n",
      "calendar_update 27\n",
      "recipe 24\n",
      "oos 992\n",
      "There are 17 misclassified for a threshold of 23\n",
      "There are 1403 total fail count for mistakes with a thrshold above 23\n"
     ]
    }
   ],
   "source": [
    "#Print all intent that have number of mistakes > threshold\n",
    "threshold = 23\n",
    "print(\"gpt3-3\")\n",
    "print_fail(processed_results_gpt3, threshold)\n",
    "print(\"===============\")\n",
    "print(\"gpt4-3\")\n",
    "print_fail(processed_results_gpt4, threshold)\n",
    "print(\"===============\")\n",
    "print(\"gpt3-1\")\n",
    "print_fail(processed_results_gpt3_1, threshold)\n",
    "print(\"===============\")\n",
    "print(\"gpt4-1\")\n",
    "print_fail(processed_results_gpt4_1, threshold)\n",
    "print(\"===============\")\n",
    "print(\"gpt_bart\")\n",
    "print_fail(processed_results_bart, threshold)\n",
    "print(\"===============\")\n",
    "print(\"gpt_bart_corr\")\n",
    "print_fail(processed_results_bart_corr, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt3_multi_fail': 21, 'gpt3_top1': 8, 'gpt3_top2': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_results_bart[\"how_busy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is the resataurant busy at 5:00 pm\n",
      "{'top1': 'recipe'}\n",
      "how busy is the cafe at 7:00\n",
      "{'top1': 'how_busy'}\n",
      "would tio's be crowded at 7\n",
      "{'top1': 'how_busy'}\n",
      "can i get a table for four at 8:00\n",
      "{'top1': 'restaurant_reservation'}\n",
      "is the friday's full after 4\n",
      "{'top1': 'how_busy'}\n",
      "how long is the wait at fridays\n",
      "{'top1': 'weather'}\n",
      "is the mexican place crowded at night\n",
      "{'top1': 'how_busy'}\n",
      "are cool people at the bar at 9:00 pm\n",
      "{'top1': 'application_status'}\n",
      "what is the best time to go to get a burger without a line\n",
      "{'top1': 'recipe'}\n",
      "how long before i can eat at chic fil a\n",
      "{'top1': 'restaurant_reviews'}\n",
      "how long to be seated at carrabas\n",
      "{'top1': 'accept_reservations'}\n",
      "is the wait at pizza hut long\n",
      "{'top1': 'recipe'}\n",
      "is the breakfast place full in the mornings\n",
      "{'top1': 'how_busy'}\n",
      "is the wait more than an hour at the italian place\n",
      "{'top1': 'weather'}\n",
      "tell me how busy red robin is at 5 pm\n",
      "{'top1': 'how_busy'}\n",
      "i wanna know how busy denny's is at 5 am\n",
      "{'top1': 'how_busy'}\n",
      "i need to know how busy denny's is at 6 am\n",
      "{'top1': 'how_busy'}\n",
      "how busy is red robin around 5 pm\n",
      "{'top1': 'how_busy'}\n",
      "so how busy is the outback steakhouse at 5 pm\n",
      "{'top1': 'how_busy'}\n",
      "tell me mr joes pizza average wait time\n",
      "{'top1': 'restaurant_reviews'}\n",
      "is mr joes pizza available for a seating\n",
      "{'top1': 'accept_reservations'}\n",
      "does mr joes pizza usually have a long wait\n",
      "{'top1': 'accept_reservations'}\n",
      "can you find out the waiting times for mr joes pizza\n",
      "{'top1': 'restaurant_reviews'}\n",
      "what's the typical wait time for mr joes pizza\n",
      "{'top1': 'restaurant_reviews'}\n",
      "how busy is cheesecake factory right now\n",
      "{'top1': 'how_busy'}\n",
      "how long is the wait at cheesecake factory\n",
      "{'top1': 'recipe'}\n",
      "how long will i have to wait at cheesecake factory\n",
      "{'top1': 'recipe'}\n",
      "is cheesecake factory busy right now\n",
      "{'top1': 'how_busy'}\n",
      "check how busy cheesecake factory is\n",
      "{'top1': 'how_busy'}\n",
      "is there a long wait at chili's around 5:00\n",
      "{'top1': 'application_status'}\n",
      "Total of 13 predicted correctly out of 30\n"
     ]
    }
   ],
   "source": [
    "#Print sample for specific intent\n",
    "print_samples(gpt4_top1, \"how_busy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt3_multi_fail': 992, 'gpt3_top2': 2, 'gpt3_top3': 4, 'gpt3_top1': 2}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_results_bart_corr[\"oos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt3_top3': 293, 'gpt3_top1': 583, 'gpt3_multi_fail': 113, 'gpt3_top2': 11}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_results_gpt4[\"oos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt3_multi_fail': 379, 'gpt3_top1': 621}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_results_gpt4_1[\"oos\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
